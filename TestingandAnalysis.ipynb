{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentimentAnalysisbert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PudLCDMotk3",
        "colab_type": "code",
        "outputId": "749c8e7d-7421-4038-bbd9-f6b2ec90a4a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "# install the required bert pretrained model\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 7.5MB/s \n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.11.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.14.15)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert, pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2prOgqx1o-2o",
        "colab_type": "code",
        "outputId": "c1669c58-eced-45e8-e2f4-8dbbd873f8d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import re\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vcpPqb8ozSo",
        "colab_type": "code",
        "outputId": "c2b07456-4b7d-4b02-f691-dbcc3d70b799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqio7Uq4pG4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_tweet(tweet):\n",
        "\t#Preprocess the text in a single tweet\n",
        "\t#arguments: tweet = a single tweet in form of string \n",
        "\t#convert the tweet to lower case\n",
        "\ttweet.lower()\n",
        "\t#convert all urls to sting \"URL\"\n",
        "\ttweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
        "\t#convert all @username to \"at_user\"\n",
        "  #tweet = re.sub('@[^\\s]+','AT_USER', tweet)\n",
        "\t#correct all multiple white spaces to a single white space\n",
        "\ttweet = re.sub('[\\s]+', ' ', tweet)\n",
        "\t#convert \"#topic\" to just \"topic\"\n",
        "\ttweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
        "\treturn tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD_I1y1PpQw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPgZ77uvpgwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'classifier.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model.load_state_dict(torch.load(path))\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH84w6b7prjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4 = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/testdata.manual.2009.06.14.csv',encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G145Ydspwza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4 = df4[['@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.','4']]\n",
        "df4.rename(columns={'@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.':'text'},inplace=True)\n",
        "df4.rename(columns={'4':'sentiment'},inplace=True)\n",
        "#df4.head()\n",
        "sentences1 = df4.text.values\n",
        "def convert_to_year(date_in_some_format):\n",
        "  if int(date_in_some_format) == 4:\n",
        "    date_in_some_format = 1\n",
        "  return int(date_in_some_format)\n",
        "\n",
        "df4['sentiment'] = df4['sentiment'].apply(convert_to_year)\n",
        "#df4.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIhB5YYCUHQV",
        "colab_type": "code",
        "outputId": "0cd6fcc9-d5b6-4e57-bac8-0f802039ba92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "df4['text'] = df4['text'].apply(preprocess_tweet)\n",
        "#df4.head()\n",
        "sentences1 = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences1]\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts1 = [tokenizer.tokenize(sent) for sent in sentences1]\n",
        "#print (\"Tokenize the first sentence:\")\n",
        "#print (tokenized_texts1[0])\n",
        "\n",
        "MAX_LEN = df4.text.map(lambda x: len(x)).max() + 12\n",
        "\n",
        "input_ids1 = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts1],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "input_ids1 = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts1]\n",
        "input_ids1 = pad_sequences(input_ids1, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "attention_masks1 = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids1:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks1.append(seq_mask)\n",
        "input_ids1\n",
        "labels = df4.sentiment.values\n",
        "type(labels)\n",
        "type(labels[0])\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)\n",
        "prediction_inputs = torch.tensor(input_ids1)\n",
        "prediction_masks = torch.tensor(attention_masks1)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 4\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "model.eval()\n",
        "# Tracking variables \n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "  eval_accuracy += tmp_eval_accuracy\n",
        "  nb_eval_steps += 1\n",
        "\n",
        "print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36lcBM35sd2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install emoji\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxuayggcqVcR",
        "colab_type": "code",
        "outputId": "b63b7668-2871-495e-da70-754c95ed5692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/')\n",
        "from old_tweets1 import *\n",
        "df5 = collect_tweets(\"samsung\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all modules uceesflly imported\n",
            "emoji\n",
            "                                                text              location\n",
            "0  Wow I'm eligible to win a Samsung Galaxy S20 ....              Dehradun\n",
            "1  Check out this Amazon deal: Galaxy Tab A 8.0 2...                      \n",
            "2  @SamsungHelpUK just got on board with Samsung ...  Somewhere in England\n",
            "3  @JustinStoutArt Definitely redundant. It's not...         Cleveland, OH\n",
            "4  Samsung Galaxy A21 Specifications Suggested on...                      \n",
            "lower\n",
            "                                                text              location\n",
            "0  wow i'm eligible to win a samsung galaxy s20 ....              Dehradun\n",
            "1  check out this amazon deal: galaxy tab a 8.0 2...                      \n",
            "2  @samsunghelpuk just got on board with samsung ...  Somewhere in England\n",
            "3  @justinstoutart definitely redundant. it's not...         Cleveland, OH\n",
            "4  samsung galaxy a21 specifications suggested on...                      \n",
            "punct\n",
            "                                                text              location\n",
            "0  wow im eligible to win a samsung galaxy s20  h...              Dehradun\n",
            "1  check out this amazon deal galaxy tab a 80 201...                      \n",
            "2  samsunghelpuk just got on board with samsung c...  Somewhere in England\n",
            "3  justinstoutart definitely redundant its not ab...         Cleveland, OH\n",
            "4  samsung galaxy a21 specifications suggested on...                      \n",
            "stop\n",
            "                                                text              location\n",
            "0  wow im eligible win samsung galaxy s20 cool qu...              Dehradun\n",
            "1  check amazon deal galaxy tab 80 2019 rugged ca...                      \n",
            "2  samsunghelpuk got board samsung cloud thought ...  Somewhere in England\n",
            "3  justinstoutart definitely redundant companies ...         Cleveland, OH\n",
            "4  samsung galaxy a21 specifications suggested be...                      \n",
            "urls\n",
            "                                                text              location\n",
            "0  wow im eligible win samsung galaxy s20 cool qu...              Dehradun\n",
            "1  check amazon deal galaxy tab 80 2019 rugged ca...                      \n",
            "2  samsunghelpuk got board samsung cloud thought ...  Somewhere in England\n",
            "3  justinstoutart definitely redundant companies ...         Cleveland, OH\n",
            "4  samsung galaxy a21 specifications suggested be...                      \n",
            "success\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHZUoNJduJUK",
        "colab_type": "code",
        "outputId": "28cf7866-118c-4442-f38f-caf5ed1cb5c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "sentences1 = df5.text.values\n",
        "#df5.head(10)\n",
        "#print(sentences1)\n",
        "sentences1 = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences1]\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "tokenized_texts1 = [tokenizer.tokenize(sent) for sent in sentences1]\n",
        "#print (\"Tokenize the first sentence:\")\n",
        "#print (tokenized_texts1[0])\n",
        "\n",
        "MAX_LEN = df5.text.map(lambda x: len(x)).max()+10\n",
        "\n",
        "\n",
        "\n",
        "input_ids1 = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts1],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "input_ids1 = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts1]\n",
        "input_ids1 = pad_sequences(input_ids1, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "attention_masks1 = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids1:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks1.append(seq_mask)\n",
        "input_ids1\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)\n",
        "prediction_inputs = torch.tensor(input_ids1)\n",
        "prediction_masks = torch.tensor(attention_masks1)\n",
        "batch_size = 4\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "i = -1\n",
        "for batch in prediction_dataloader:\n",
        "  i += 1\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "  def find_this(pred1):\n",
        "    if pred1 == 1:\n",
        "      v = \"positive\"\n",
        "    elif pred1 == 0:\n",
        "      v = \"negative\"\n",
        "    else:\n",
        "      v = \"neutral\"\n",
        "    return v\n",
        "  k = -1\n",
        "  for j in range(i*batch_size,(i*batch_size)+batch_size):\n",
        "    k += 1\n",
        "    print(df5['text'][j],find_this(pred_flat[k]))\n",
        "  #print(df5['text'][i*batch_size:(i*batch_size)+batch_size],pred_flat)\n",
        "  #3break\n",
        "  if i == 3:\n",
        "    break\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wow im eligible win samsung galaxy s20 cool quiztimemorningswithamazon samsunggalaxys20 httpstcozabijdxb3r neutral\n",
            "check amazon deal galaxy tab 80 2019 rugged case kickstandsmt290 smt295 poetic full body shoc… httpstcopgx1vx0vti neutral\n",
            "samsunghelpuk got board samsung cloud thought id use handy download feature windows its… httpstcofireovqgcf neutral\n",
            "justinstoutart definitely redundant companies caring ecosystem apple… httpstcovendksijpf negative\n",
            "samsung galaxy a21 specifications suggested benchmark site httpstcoljfyz4j2s3 httpstcowsaev59ade neutral\n",
            "galaxys20quiz surprise samsung httpstcoms4vc857nf positive\n",
            "1raghvan1 thank writing request use support channels team happy h… httpstcogaslsdmayz positive\n",
            "samsung e apple httpstcoghajkipmlm neutral\n",
            "ready stock flipcoverbookcoversilicon andromaxsamsung galaxyblackberryiphone fast respone add pin 32a834ab 08891047101 positive\n",
            "hibiscus amp moon captured 03 dec 2017 full moon night day time using samsung e5… httpstcorzxy3xvi8p neutral\n",
            "today casspernyovest djfreshsa setting samsungmobilesa galaxys20studio sandton city ablaze… httpstcoihbm5fkqqh neutral\n",
            "march 14 2020 0530am buy oneplus device smoothos 90hz oneplus7tpro neversettle beyondthespeed… httpstcoctmmkxaqsl negative\n",
            "tweeted via samsung smart tv internet browser neutral\n",
            "innovation love samsung galaxys20 refreshing rate display 120hz highvoltagehighvoltageso smooth fast smilingfacewithhearteyes samsungid positive\n",
            "samsung galaxy tab s5e unboxing setup samsung galaxy s5e android technology tech review unboxing… httpstcoe2wngjlix1 neutral\n",
            "fucking love samsung face look porelezzz httpstcox1vnemohbv positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRzLUMJ50rG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(df5['text'][9],pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqg9Xyp00sH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}